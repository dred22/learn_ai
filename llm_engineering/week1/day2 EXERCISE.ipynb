{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality content such as articles, social media posts, and product descriptions. This can help businesses save time and resources on content creation while maintaining a high level of quality.\n",
      "2. **Product Design**: Generative AI can be used to design new products, such as furniture, electronics, or clothing. This can help businesses reduce the cost and time associated with traditional product design methods.\n",
      "3. **Marketing Campaigns**: Generative AI can be used to generate personalized marketing campaigns, including email marketing, social media ads, and influencer partnerships. This can help businesses target specific audiences more effectively.\n",
      "4. **Customer Service Chatbots**: Generative AI can be used to create chatbots that can understand and respond to customer inquiries in a more human-like way.\n",
      "5. **Financial Analysis**: Generative AI can be used to analyze large amounts of financial data, identify trends, and make predictions about future market movements.\n",
      "6. **Language Translation**: Generative AI can be used to translate languages in real-time, helping businesses communicate with customers and partners who speak different languages.\n",
      "7. **Image and Video Generation**: Generative AI can be used to generate high-quality images and videos for marketing purposes, such as product demonstrations or explainer videos.\n",
      "8. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and maintenance needs, helping businesses reduce downtime and improve efficiency.\n",
      "9. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations, including predicting demand, managing inventory, and identifying potential bottlenecks.\n",
      "10. **Cybersecurity Threat Analysis**: Generative AI can be used to analyze large amounts of network traffic data and identify potential security threats in real-time.\n",
      "\n",
      "Some specific use cases include:\n",
      "\n",
      "* **Amazon's AI-powered product recommendations**: Amazon uses generative AI to suggest products to customers based on their browsing history and purchase behavior.\n",
      "* **Google's AI-powered content moderation**: Google uses generative AI to moderate online content, helping to reduce hate speech and misinformation.\n",
      "* **IBM's AI-powered customer service chatbots**: IBM uses generative AI to create chatbots that can understand and respond to customer inquiries in a more human-like way.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases emerge.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality content such as images, videos, music, and text, without human intervention. This can save time and resources for businesses looking to produce large quantities of content.\n",
      "2. **Marketing and Advertising**: Generative AI can help create personalized marketing messages, product recommendations, and ad creatives, leading to more effective advertising campaigns.\n",
      "3. **Product Design and Development**: Generative AI can be used to design new products, such as furniture, electronics, or fashion items, using computer-aided design (CAD) software.\n",
      "4. **Image and Video Editing**: Generative AI-powered tools can automatically edit images and videos, removing noise, correcting colors, and enhancing overall quality.\n",
      "5. **Data Analysis and Visualization**: Generative AI can be used to analyze large datasets, identify patterns, and create visualizations that help businesses make data-driven decisions.\n",
      "6. **Customer Service Chatbots**: Generative AI-powered chatbots can provide 24/7 customer support, answering frequently asked questions and resolving simple issues.\n",
      "7. **Language Translation**: Generative AI can help translate languages in real-time, enabling international communication and collaboration.\n",
      "8. **Creative Writing and Storytelling**: Generative AI can be used to generate creative content such as articles, blog posts, and even entire books.\n",
      "9. **Music Composition and Production**: Generative AI can assist musicians in composing music, creating beats, and producing tracks.\n",
      "10. **Financial Modeling and Predictive Analytics**: Generative AI can help businesses create predictive models for financial forecasting, risk assessment, and portfolio optimization.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Chatbots**: Companies like Amazon, IBM, and Facebook use generative AI-powered chatbots to provide customer support.\n",
      "* **Content Generation**: Companies like Buzzfeed, Hootsuite, and LinkedIn use generative AI to create content for their platforms.\n",
      "* **Product Design**: Companies like IKEA, Nike, and Adidas use generative AI to design new products and improve existing ones.\n",
      "* **Marketing Automation**: Companies like Salesforce, HubSpot, and Marketo use generative AI to automate marketing campaigns.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As this technology continues to evolve, we can expect even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content, such as:\n",
      " * Images (e.g., product images, blog graphics)\n",
      " * Videos (e.g., explainer videos, social media clips)\n",
      " * Text (e.g., articles, website copy, product descriptions)\n",
      " * Music and audio tracks\n",
      "2. **Marketing and Advertising**: Generative AI can help with:\n",
      " * Personalized customer experience: creating highly engaging ad content tailored to individual customers.\n",
      " * Content personalization: adjusting the tone and style of ads to suit specific audiences.\n",
      " * Social media management: generating high-quality social media posts, stories, and videos.\n",
      "3. **Design and Product Development**: Generative AI can aid in:\n",
      " * Product design: generating 2D and 3D designs for products, packaging, and prototypes.\n",
      " * Fashion design: creating conceptual designs for clothing items and accessories.\n",
      " * Interior design: generating room layouts and decoration ideas.\n",
      "4. **Accounting and Finance**: Generative AI can assist with:\n",
      " * Financial forecasting: predicting expenses, revenues, and cash flow.\n",
      " * Tax preparation: automating tax returns and generating accurate calculations.\n",
      " * Credit risk assessment: analyzing financial data to predict creditworthiness.\n",
      "5. **Customer Service and Support**: Generative AI-powered chatbots can:\n",
      " * Provide personalized customer support\n",
      " * Respond to frequently asked questions\n",
      " * Automate basic inquiries and complaints\n",
      "6. **Data Analysis and Insights**: Generative AI can help with:\n",
      " * Data visualization: creating interactive visualizations of complex data sets.\n",
      " * Predictive analytics: generating accurate forecasts based on predictive models.\n",
      " * Recommendations: suggesting products or services based on user behavior and preferences.\n",
      "7. **Supply Chain Optimization**: Generative AI can aid in:\n",
      " * Demand forecasting: predicting demand for products across different regions and time periods.\n",
      " * Inventory management: adjusting inventory levels to minimize stockouts and overstocking.\n",
      " * Logistics optimization: streamlining delivery routes and reducing transportation costs.\n",
      "8. **Hiring and Recruitment**: Generative AI can assist with:\n",
      " * Job matching: matching candidates with job openings based on skills and preferences.\n",
      " * Resumé screening: filtering through resumes to identify potential candidates.\n",
      "9. **Personalized Medicine and Science**: Generative AI can help in:\n",
      " * Drug discovery: predicting potential drug efficacy and safety profiles.\n",
      " * Cancer research: analyzing genomic data to identify patterns and potential treatments.\n",
      "\n",
      "These are just a few examples of the business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand what defines a language model (LLM) in the context of large language models. I know that an LLM is something like ChatGPT or GPT-3, but I want to break down each part of it because the user asked for definitions of some core concepts: neural network, attention, and transformer. \n",
      "\n",
      "First, a neural network (NN). Hmm, maybe it's similar to how our brains work? We have lots of neurons that process information. So, a neural network should do something like recognize patterns or make predictions based on data. But how does that translate into an LLM? Maybe the NN processes each word in a sentence and uses some weights (like learnable parameters) in their connections to adjust outputs. Like, training the model involves learning these weights so it can generate responses better.\n",
      "\n",
      "Then, what about attention? I've heard that models like attention have something called \"attention layers\" where they can focus on specific parts of the input. For example, maybe you look at certain words at once rather than whole sentences. This makes the model more efficient because it doesn't mix all information, right? So, attention adjusts how much each part takes from other parts based on some similarity or alignment.\n",
      "\n",
      "Now, the transformer. The user mentioned the Vaswani architecture—maybe that's like multi-head self-attention. Each head can attend to different positions in the input sequence, giving it a lot of flexibility. Also, recurrent layers for processing sequences, maybe something like LLMs use LSTMs or other RNN mechanisms to remember past context. It connects token-wise queries and keys with values using attention mechanism. So, perhaps each model is made of multiple attention layers where different parts talk to different contexts.\n",
      "\n",
      "Putting it all together: an LLM uses a neural network's structure (with lots of parameters, learnable weights) to process inputs, which can then use an attention-based architecture where different parts pay attention based on similarity, and this helps the model to focus on relevant elements without mixing everything up. The transformer does this efficiently with multiple attention heads focusing on specific parts of the input in parallel, allowing each head to process its own context while still maintaining some global understanding from previous steps.\n",
      "\n",
      "I think that's a good outline. But I should check if there are other components, like how models handle token interleaving or memory management—maybe via RNNs or attention-based mechanisms processing step by step, similar to sequential processing in sentence generation tasks.\n",
      "</think>\n",
      "\n",
      "A language model (LLM) is a type of advanced machine learning model inspired by the human ability to process and generate language. Here's a breakdown of its core components:\n",
      "\n",
      "1. **Neural Network**: Represents the model's architecture using layers composed of neurons connected with weights and biases. Each neuron processes input through weighted connections, adjusting outputs based on learnable parameters during training.\n",
      "\n",
      "2. **Attention Mechanism**: Transferring focus to specific parts of the input sequence by aligning or combining information from different positions. This reduces reliance on whole sentences or sequences, making models more efficient.\n",
      "\n",
      "3. **Transformer Architecture**: Empires like multi-head self-attention in Vaswani (LMN) layers, where each head focuses on different context windows with attention weights determined by similarities between token pairs. Recurrent components process messages sequentially, as seen in LSTMs or other RNNs.\n",
      "\n",
      "These elements work together: the neural network processes individual words and uses attention to focus on relevant contexts, while the transformer's multi-head mechanism efficiently handles parallel processing for tasks like generating sequences.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec63e70-d7ce-409f-987e-1dc909ee0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d937149-6224-4665-940a-f5d2091bf1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79655f57-ea62-41c3-a371-15d58fb8cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c7f2ba6-2a2a-43e1-b188-6daf6ea18af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "    \n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = \"deepseek-r1:1.5b\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e3efac-28e3-4245-9c34-dec18de865d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Summary**\\n\\nThe website \"Home - Edward Donner\" appears to be a personal website or blog, primarily focused on the founder Ed\\'s work and interests in AI (Artificial Intelligence) development, particularly in the field of Large Language Models (LLMs).\\n\\n### Notable Content\\n\\n- **Nebula.io**: The co-founder and CTO of Nebula.io, an AI startup that applies AI to help people discover their potential. \\n- **Projects and Courses**: Various courses and resources on AI and LLMs, including \"Become an LLM expert and leader\" course, and the \"LLM Workshop – Hands-on with Agents – resources\".\\n- **Announcements** :\\n  - \"Connecting my courses (May 28, 2025)\": A new development in Ed\\'s educational platforms for learning about AI.\\n  - \"2025 AI Executive Briefing (April 21, 2025)\": An event focused on discussing the applications and possibilities of AI in various industries.\\n\\n- **Personal Information**:\\n  - DJing enthusiast\\n  - Amateur electronic music producer\\n\\n- **Newsletters**: A subscription system that allows users to get updates from Ed Donner\\'s content.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15386edc-b995-4cc4-a4fe-289e50869aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1964fa4f-0766-4b6b-ab84-efc5bc079198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, I need to respond to this user's query. First, they want a summary of a website titled Home - Edward Donner. The content talks about Connect Four, Outsmart, an AI arena, and some about the company Nebula.io.\n",
       "\n",
       "I should make sure not to mention any navigation links like \"Connect Four\" or \"Outsmart.\" I'll focus on the main features: Connect Four for games, Outsmart for competitive skill assessment, and talk about the companies involved. Also, they emphasized summarizing news/announcements in separate points.\n",
       "\n",
       "The user requested a markdown response, so I need to format it correctly without any links except for the website URL. I should list key features step by step, summarize each feature if relevant, mention the company's background with their AIs, and note any notable news or press.\n",
       "\n",
       "I'll structure the summary clearly, ensuring it's concise but covers all important aspects mentioned in the original content.\n",
       "</think>\n",
       "\n",
       "Certainly! Here's a concise markdown summary of the website:\n",
       "\n",
       "---\n",
       "\n",
       "**Home - Edward Donner**\n",
       "\n",
       "The website presents a variety of games and competitions, with Connect Four being a prominent feature. It is designed for players to connect pieces horizontally, vertically, or diagonally in Connect Four-like gameplay. Outsmart adds another layer by offering live skill assessments to keep competitors on their toes. The site also features an AI arena, where participants can test their LLM (Large Language Model) skills against others, showcasing advanced computational abilities.\n",
       "\n",
       "The company edwarddonner.com is mentioned along with its work in artificial intelligence applications. Notable releases include the connect four game and a feature called the \"500 Best LLM Games.\" The site is supported by a newsletter for updates and news related to its innovative features.\n",
       "\n",
       "--- \n",
       "\n",
       "Let me know if you'd like further elaboration!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70503d-b0eb-44cc-87b4-2c065fca4648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
